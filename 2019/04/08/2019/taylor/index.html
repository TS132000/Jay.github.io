<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/logo_miccall.png"/>
	<link rel="shortcut icon" href="/img/logo_miccall.png">
	
			    <title>
    Mr.Zhai
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="Serendipity" />
    
    	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/bg.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
<meta name="generator" content="Hexo 4.2.1"></head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">Serendipity</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">主页</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">分类</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="category-link" href="/categories/To-do-list/">To do list</a></li><li><a class="category-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a></li><li><a class="category-link" href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a></li><li><a class="category-link" href="/categories/%E6%AF%8F%E6%97%A5%E8%AE%B0%E5%BD%95/">每日记录</a></li><li><a class="category-link" href="/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/">环境配置</a>
	                    </ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        <li class="active">
	            <a href="#s1">归档</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="archive-link" href="/archives/2020/06/">June 2020</a></li><li><a class="archive-link" href="/archives/2019/10/">October 2019</a></li><li><a class="archive-link" href="/archives/2019/08/">August 2019</a></li><li><a class="archive-link" href="/archives/2019/05/">May 2019</a></li><li><a class="archive-link" href="/archives/2019/04/">April 2019</a>
	                    </ul>
	        </li>
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/blog/" title="学习记录">
		                学习记录
		            </a>
		        </li>
		        
		        <li>
		            <a href="/note/" title="日常随笔">
		                日常随笔
		            </a>
		        </li>
		        
		        <li>
		            <a href="/experience/" title="项目经历">
		                项目经历
		            </a>
		        </li>
		        
		        <li>
		            <a href="/about/" title="个人简历">
		                个人简历
		            </a>
		        </li>
		        
		        <li>
		            <a href="/gallery/" title="一些收藏">
		                一些收藏
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/miccall" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
                    <li>
                        <a title="500px" href="http://500px.com" target="_blank" rel="noopener">
                            <i class="icon fa fa-500px"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height: 25rem;background-image: url(https://note.youdao.com/yws/api/personal/file/83D52368A1DA41EDA325FB2FE678D81B?method=download&amp;shareKey=887b1bbc795259bffda94ff12f275403);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2 >机器学习回顾---逻辑回归</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <h1 id="机器学习回顾1：回归"><a href="#机器学习回顾1：回归" class="headerlink" title="机器学习回顾1：回归"></a>机器学习回顾1：回归</h1><h4 id="逻辑回归解决分类问题"><a href="#逻辑回归解决分类问题" class="headerlink" title="逻辑回归解决分类问题"></a>逻辑回归解决分类问题</h4><p>0.概述：<br>适用问题举例：预测结果是否为一个类，如判断垃圾邮件，肿瘤分类，判断金融交易是否为商业欺诈。<br>以上问题都属于二元分类，实例结果y == 0 or 1，因此需要建立模型h(x),使预测值分布在0/1之间，若用线性回归，则输出值可能远大于1或小于0，所以引入逻辑回归算法，使输出值在0/1分布。</p>
<h5 id="（一）逻辑回归"><a href="#（一）逻辑回归" class="headerlink" title="（一）逻辑回归"></a>（一）逻辑回归</h5><blockquote>
<p>适用于标签y取离散值的情况，如：[1 0 0 1]</p>
</blockquote>
<p>1) 函数模型 ：sigmoid 函数</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/0AE06CE2CF7E4A16BA03E0C57284E64F?method=download&shareKey=b932568d7112625d9fbde9906d52e5e1" alt=""><br>输出结果为0/1之间的一个值，若g(z)=0.7，则偏向正向类概率为70%</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/43244A1F171D4CAA9A378FCE63521ECF?method=download&shareKey=5aea67b80ec8d342d41b9dc41c90857e" alt=""></p>
<p>代码实现</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">def sigmoid (z):</span><br><span class="line">    return 1&#x2F;(1+np.exp(-z)</span><br></pre></td></tr></table></figure>



<p>2)代价函数：<br><img src="https://note.youdao.com/yws/api/personal/file/DD68D2FECADA47CD8591661A10BC0F7E?method=download&shareKey=798abf91f1c042072b6f07620487ae96" alt=""></p>
<p>简化版：<br><img src="https://note.youdao.com/yws/api/personal/file/1D67CB9D1C174FAFB383704160B608B9?method=download&shareKey=27545f10236f44c792bea2663484cd06" alt=""></p>
<p>代码实现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">def costFuc(theta,X,y):</span><br><span class="line">    theta &#x3D; np.matrix(theta)</span><br><span class="line">    X &#x3D; np.matrix(X)</span><br><span class="line">    y &#x3D; np.matrix(y)</span><br><span class="line">    first &#x3D; np.mutiply(-y,np.log(sigmiod(X*theta.T)))</span><br><span class="line">    second &#x3D; np.mutiply((1-y),np.log(1-sigmoid(X*theta.T)))</span><br><span class="line">    return np.sum(first-second)&#x2F;(len(X))</span><br></pre></td></tr></table></figure>
<p>得到代价函数后，应用梯度下降求得最优参数，特征放缩同样适用。</p>
<h4 id="多类别分类：一对多"><a href="#多类别分类：一对多" class="headerlink" title="多类别分类：一对多"></a>多类别分类：一对多</h4><p>相对于二元分类y=[1,0,0,1]</p>
<p>多类别分类 y = [1,2,3,4]</p>
<p>如自动将邮件归类为 1同学 2家人 3广告 4工作</p>
<p>药物诊断 1没病 2感冒 3流感 etc</p>
<blockquote>
<p>实现方法：创建新的“伪训练集”，使用“一” 对 “余” 的方法</p>
</blockquote>
<h6 id="举例说明："><a href="#举例说明：" class="headerlink" title="举例说明："></a>举例说明：</h6><p><img src="https://note.youdao.com/yws/api/personal/file/D91AC54B42D14255834325193BFEE266?method=download&shareKey=be13f1dc171e3707d55013a432c322a8" alt=""></p>
<blockquote>
<p>对于三元分类问题，可以拆解成三个二元分类问题，由此构建三个分类器。<br>做预测时，在三个分类器中输入x，选择概率中的最大值，即为预测值</p>
</blockquote>
<p><img src="https://note.youdao.com/yws/api/personal/file/74906DD4F8D045CDBEC5B3FE44D4837C?method=download&shareKey=9662787c4ba66f44875f9e7ae6452722" alt=""></p>
<h1 id="机器学习回顾2：正则化解决过拟合问题"><a href="#机器学习回顾2：正则化解决过拟合问题" class="headerlink" title="机器学习回顾2：正则化解决过拟合问题"></a>机器学习回顾2：正则化解决过拟合问题</h1><h3 id="正则化解决过拟合问题"><a href="#正则化解决过拟合问题" class="headerlink" title="正则化解决过拟合问题"></a>正则化解决过拟合问题</h3><blockquote>
<p>过拟合问题通常有两种解决方法：</p>
</blockquote>
<blockquote>
<p>1.丢弃一些对正确预测没作用的特征，人工选择或借助算法模型（如PCA）</p>
</blockquote>
<blockquote>
<p>2.正则化，保留特征，但减小参数大小</p>
</blockquote>
<p>(一)代价函数正则化</p>
<p>1.方式：通过对影响过拟合的项进行惩罚处理，减小其影响,特征较多时，对所有特征惩罚，让代价函数最优化软件选择惩罚程度。得到如下假设：</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/728A6AB534294973A67E7BFF43B0EE59?method=download&shareKey=5520feade9c7d0d8fd9b33f076144bb4" alt=""></p>
<p>令λ很大，可以将所有参数值减小，削弱其影响程度。</p>
<p>(二)正则化线性回归<br><img src="https://note.youdao.com/yws/api/personal/file/728A6AB534294973A67E7BFF43B0EE59?method=download&shareKey=5520feade9c7d0d8fd9b33f076144bb4" alt=""></p>
<p><img src="https://note.youdao.com/yws/api/personal/file/BA35A4FB1AF04A1A98A7960170E741DB?method=download&shareKey=1f8dfe50ddebbdcc0237b672a4129c7f" alt=""></p>
<p>(二)正则化逻辑回归</p>
<p>代价函数：<br><img src="https://note.youdao.com/yws/api/personal/file/03024CEC064844FA8FE08B3AD4059086?method=download&shareKey=1cbd8c9235245e62deea88037eea7421" alt=""></p>
<p>梯度下降<br><img src="https://note.youdao.com/yws/api/personal/file/BA35A4FB1AF04A1A98A7960170E741DB?method=download&shareKey=1f8dfe50ddebbdcc0237b672a4129c7f" alt=""></p>
<blockquote>
<p>注：线性回归与逻辑回归的正则化梯度下降虽然形式相同，但是二者h(x)不同，所以有很大差别。</p>
</blockquote>
<h1 id="机器学习回顾3：一个简单的一元线性回归应用—-工资预测"><a href="#机器学习回顾3：一个简单的一元线性回归应用—-工资预测" class="headerlink" title="机器学习回顾3：一个简单的一元线性回归应用—-工资预测"></a>机器学习回顾3：一个简单的一元线性回归应用—-工资预测</h1><blockquote>
<p>通过单一工龄变量，建立一元线性回归预测模型，实现工资预测</p>
</blockquote>
<p>1.数据集</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/6CF4C8BC039941F9B1D6EF19771898B2?method=download&shareKey=410b758746fd818b6fb75ec989a9963c" alt=""></p>
<p><img src="https://note.youdao.com/yws/api/personal/file/CF293EF45E3F4C2484E035161F3A2A48?method=download&shareKey=3cfc62bf39980b1e7011280498df5e74" alt=""></p>
<p>2.数据集处理</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 导入工具包</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"># 导入数据集</span><br><span class="line">dataset &#x3D; pd.read_csv(&#39;Salary_Data.csv&#39;)</span><br><span class="line">X &#x3D; dataset.iloc[:, :-1].values</span><br><span class="line">y &#x3D; dataset.iloc[:, 1].values</span><br><span class="line"></span><br><span class="line"># 分割训练集，测试集</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test &#x3D; train_test_split(X, y, test_size &#x3D; 1&#x2F;3, random_state &#x3D; 0)</span><br></pre></td></tr></table></figure>

<p>3.建立模型并拟合，做出对测试集的预测</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 建立模型，拟合</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">regressor &#x3D; LinearRegression()</span><br><span class="line">regressor.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"># 预测</span><br><span class="line">y_pred &#x3D; regressor.predict(X_test)</span><br></pre></td></tr></table></figure>

<p>4.可视化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 可视化训练集</span><br><span class="line">plt.scatter(X_train, y_train, color &#x3D; &#39;red&#39;)</span><br><span class="line">plt.plot(X_train, regressor.predict(X_train), color &#x3D; &#39;blue&#39;)</span><br><span class="line">plt.title(&#39;Salary VS Experience (training set)&#39;)</span><br><span class="line">plt.xlabel(&#39;Years of Experience&#39;)</span><br><span class="line">plt.ylabel(&#39;Salary&#39;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>




<p><img src="https://note.youdao.com/yws/api/personal/file/FDC5236CC2CC41F687B1884985AA84C4?method=download&shareKey=e17a5ce5a0450702f44f207280d43ef6" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 可视化测试集，查看预测效果</span><br><span class="line">plt.scatter(X_test, y_test, color &#x3D; &#39;red&#39;)</span><br><span class="line">plt.plot(X_train, regressor.predict(X_train), color &#x3D; &#39;blue&#39;)</span><br><span class="line">plt.title(&#39;Salary VS Experience (test set)&#39;)</span><br><span class="line">plt.xlabel(&#39;Years of Experience&#39;)</span><br><span class="line">plt.ylabel(&#39;Salary&#39;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://note.youdao.com/yws/api/personal/file/1F7A5226901D420981B80ACE6D1BBF73?method=download&shareKey=5684fcedf8b345458d6d18b2d77a1761" alt=""></p>
<h1 id="机器学习回顾4：机器学习—线性回归"><a href="#机器学习回顾4：机器学习—线性回归" class="headerlink" title="机器学习回顾4：机器学习—线性回归"></a>机器学习回顾4：机器学习—线性回归</h1><h3 id="算法原理："><a href="#算法原理：" class="headerlink" title="算法原理："></a>算法原理：</h3><blockquote>
<p>利用线性函数拟合训练集，得到预测模型。矩阵化输入，利用平方误差作为损失函数，求梯度=0，得最优参（注意特征放缩，归一化）</p>
</blockquote>
<h3 id="数学推导"><a href="#数学推导" class="headerlink" title="数学推导"></a>数学推导</h3><p><img src="https://note.youdao.com/yws/api/personal/file/3cc9dd2c4cdd14ad78c34a3e879b46ed?method=download&shareKey=f5ac07ca63b243e97b3c87ce312effa8" alt=""></p>
<h3 id="代码实现实例"><a href="#代码实现实例" class="headerlink" title="代码实现实例"></a>代码实现实例</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def test_LinearRegression(*data):</span><br><span class="line">    X_train,X_test,y_train,y_test&#x3D;data</span><br><span class="line">    regr &#x3D; linear_model.LinearRegression()</span><br><span class="line">    regr.fit(X_train, y_train)</span><br><span class="line">    print(&#39;Coefficients:%s, intercept %.2f&#39;%(regr.coef_,regr.intercept_))</span><br><span class="line">    print(&quot;Residual sum of squares: %.2f&quot;% np.mean((regr.predict(X_test) - y_test) ** 2))</span><br><span class="line">    print(&#39;Score: %.2f&#39; % regr.score(X_test, y_test))</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LinearRegression(copy_X&#x3D;True, fit_intercept&#x3D;True, n_jobs&#x3D;1, normalize&#x3D;False)</span><br><span class="line">###fit_intercept 指定是否计算b值，看推导过程中的矩阵x是否有1列</span><br><span class="line">###normalize 归一化（特征放缩）</span><br></pre></td></tr></table></figure>


<h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><blockquote>
<p>通过对模型增加先验假设（惩罚项），来减小模型复杂度，根据引入不同的正则化项，有不同的回归方式。</p>
</blockquote>
<ul>
<li>岭回归（Ridge）：L2范数惩罚项</li>
<li>lasso 回归：L1范数惩罚项</li>
<li>Elastic Net：L1，L2的权衡</li>
</ul>
<h1 id="机器学习回顾5：机器学习—逻辑回归"><a href="#机器学习回顾5：机器学习—逻辑回归" class="headerlink" title="机器学习回顾5：机器学习—逻辑回归"></a>机器学习回顾5：机器学习—逻辑回归</h1><h3 id="算法原理：-1"><a href="#算法原理：-1" class="headerlink" title="算法原理："></a>算法原理：</h3><blockquote>
<p>利用对数概率函数，实现二分类，通过极大似然估计推出目标函数，再利用梯度下降法或拟牛顿法得到最优参。</p>
</blockquote>
<h3 id="数学推导-梯度下降法"><a href="#数学推导-梯度下降法" class="headerlink" title="数学推导(梯度下降法)"></a>数学推导(梯度下降法)</h3><p><img src="https://note.youdao.com/yws/api/personal/file/8c125ea62df6c7521d8c64351ff5e31a?method=download&shareKey=68e3acb33c52ae7246eaf4ec18b6b1a8" alt=""></p>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def test_LogisticRegression(*data):</span><br><span class="line">    </span><br><span class="line">    X_train,X_test,y_train,y_test&#x3D;data</span><br><span class="line">    regr &#x3D; linear_model.LogisticRegression()</span><br><span class="line">    regr.fit(X_train, y_train)</span><br><span class="line">    print(&#39;Coefficients:%s, intercept %s&#39;%(regr.coef_,regr.intercept_))</span><br><span class="line">    print(&#39;Score: %.2f&#39; % regr.score(X_test, y_test))</span><br></pre></td></tr></table></figure>

<h1 id="机器学习回顾6：机器学习—KNN"><a href="#机器学习回顾6：机器学习—KNN" class="headerlink" title="机器学习回顾6：机器学习—KNN"></a>机器学习回顾6：机器学习—KNN</h1><h3 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h3><h3 id="数学推导-1"><a href="#数学推导-1" class="headerlink" title="数学推导"></a>数学推导</h3><h3 id="代码实现实例-1"><a href="#代码实现实例-1" class="headerlink" title="代码实现实例"></a>代码实现实例</h3><ul>
<li>手写数字识别</li>
</ul>
<ol>
<li>加载分类模型使用的数据集。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">*def load_classification_data()</span><br><span class="line"></span><br><span class="line">    digits&#x3D;datasets.load_digits() # 使用 scikit-learn 自带的手写识别数据集 Digit Data</span><br><span class="line">    X_train&#x3D;digits.data</span><br><span class="line">    y_train&#x3D;digits.target</span><br><span class="line">    return train_test_split(X_train, y_train,test_size&#x3D;0.25,</span><br><span class="line">            random_state&#x3D;0,stratify&#x3D;y_train) # 进行分层采样拆分，测试集大小占 1&#x2F;4</span><br></pre></td></tr></table></figure></li>
</ol>
<p>*</p>
<h1 id="机器学习回顾7：ITK-training过程总结"><a href="#机器学习回顾7：ITK-training过程总结" class="headerlink" title="机器学习回顾7：ITK-training过程总结"></a>机器学习回顾7：ITK-training过程总结</h1><h2 id="主要做的事情"><a href="#主要做的事情" class="headerlink" title="主要做的事情"></a>主要做的事情</h2><h3 id="1-基于ITK-training复现Self-training，Co-training-算法"><a href="#1-基于ITK-training复现Self-training，Co-training-算法" class="headerlink" title="1.基于ITK-training复现Self-training，Co-training 算法"></a>1.基于ITK-training复现Self-training，Co-training 算法</h3><h5 id="学到的python基本操作"><a href="#学到的python基本操作" class="headerlink" title="学到的python基本操作"></a>学到的python基本操作</h5><ul>
<li><p>基本csv文件操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#读取csv文件</span></span><br><span class="line">train_feat = pd.read_csv(<span class="string">'train.csv'</span>, header=<span class="literal">None</span>)</span><br><span class="line"><span class="comment">#将处理后的dataframe保存为csv文件</span></span><br><span class="line">lable.to_csv(<span class="string">'label.csv'</span>)</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>基本dataframe格式操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#.ix切片 .ix[:,:]先行后列，注意初始位置会与设置不符</span></span><br><span class="line">train_feat = train_feat.ix[:, <span class="number">1</span>:]</span><br><span class="line"><span class="comment">#.iloc切片</span></span><br><span class="line">pred1 = pred_original.iloc[:<span class="number">20000</span>]</span><br><span class="line">train_feat_local = train_feat.iloc[:,<span class="number">35</span>:]</span><br><span class="line"><span class="comment">#更改列名.columns</span></span><br><span class="line">prob_test.columns = [<span class="string">'prob'</span>]</span><br><span class="line"><span class="comment">#将array，dict格式转换成dataframe格式</span></span><br><span class="line">y_true = pd.DataFrame.from_dict(y_true)</span><br><span class="line"><span class="comment">#合并两个或多个dataframe，concat，axis = 1为列合并，0为行合并</span></span><br><span class="line">data = pd.concat([prob_test, y_true], axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#dataframe按某一列值排序.sort_values,0为降序</span></span><br><span class="line">y_submission.sort_values(by=<span class="string">'prob'</span>, ascending=[<span class="number">0</span>], inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#索引值重置.reset_index</span></span><br><span class="line">prob_test= y_submission.reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>模型训练与评价</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#训练集，验证集划分</span></span><br><span class="line">x_train, x_val, y_train, y_val = train_test_split(train_feat_local, label, test_size=<span class="number">0.05</span>, random_state=<span class="number">518</span>)</span><br><span class="line"><span class="comment">#模型参数设置</span></span><br><span class="line">clf1 = xgb.XGBClassifier(max_depth=<span class="number">6</span>,</span><br><span class="line">                        learning_rate=<span class="number">0.05</span>,</span><br><span class="line">                        n_estimators=<span class="number">2000</span>,</span><br><span class="line">                        objective=<span class="string">'reg:logistic'</span>,</span><br><span class="line">                        gamma=<span class="number">0.0</span>,</span><br><span class="line">                        min_child_weight=<span class="number">1</span>,</span><br><span class="line">                        max_delta_step=<span class="number">0</span>,</span><br><span class="line">                       subsample=<span class="number">1</span>,</span><br><span class="line">                        colsample_bytree=<span class="number">0.8</span>,</span><br><span class="line">                        colsample_bylevel=<span class="number">1</span>,</span><br><span class="line">                        reg_alpha=<span class="number">0</span>,</span><br><span class="line">                        reg_lambda=<span class="number">1</span>,</span><br><span class="line">                        scale_pos_weight=<span class="number">1</span></span><br><span class="line">                        )</span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">clf1.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_val, y_val)], eval_metric=<span class="string">'logloss'</span>)</span><br><span class="line"><span class="comment">#模型预测并输出概率值，评价预测结果，recall</span></span><br><span class="line">y_submission1 = clf1.predict_proba(test_feat_local)[:, <span class="number">0</span>]</span><br><span class="line">pred_view1 = &#123;<span class="string">'id'</span>: test_id, <span class="string">'prob'</span>: y_submission1&#125;</span><br><span class="line">pred_view1 = pd.DataFrame.from_dict(pred_view1)</span><br><span class="line">pred_view1 = pd.concat([pred_view1, test_feat_local], axis=<span class="number">1</span>)</span><br><span class="line">pred_view1.sort_values(by=<span class="string">'prob'</span>, ascending=[<span class="number">0</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">pred_view1 = pred_view1.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">pred1 = pred_view1.iloc[:<span class="number">20000</span>]</span><br><span class="line">right=len(pred1[pred1.id.isin(df_9982.id.unique())])</span><br><span class="line">print(<span class="string">'round 1 clf1 right number:&#123;&#125;,score:&#123;&#125;'</span>.format(right,right*<span class="number">100.00</span>/<span class="number">20000</span>))</span><br></pre></td></tr></table></figure>
</li>
<li><p>各项指标</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 各项指标</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score,accuracy_score,recall_score,precision_score</span><br><span class="line"></span><br><span class="line">y_pred = clf1.predict(test_feat_local)</span><br><span class="line">y_pred = pd.DataFrame.from_dict(y_pred)</span><br><span class="line">y_pred.sort_values(by=<span class="number">0</span>, ascending=[<span class="number">0</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">y_pred = y_pred.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">"F1"</span>)</span><br><span class="line">print(f1_score(y_true,y_pred,average=<span class="string">'macro'</span>))</span><br><span class="line">print(<span class="string">"accuracy"</span>)</span><br><span class="line">print(accuracy_score(y_true, y_pred))</span><br><span class="line">print(<span class="string">"recall"</span>)</span><br><span class="line">print(recall_score(y_true, y_pred, average=<span class="string">'macro'</span>))</span><br><span class="line">print(<span class="string">"precision"</span>)</span><br><span class="line">print(precision_score(y_true, y_pred, average=<span class="string">'macro'</span>))</span><br></pre></td></tr></table></figure>
</li>
<li><p>按索引id剔除多行数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### create U_</span></span><br><span class="line">U = new_test_feat_original</span><br><span class="line">new_test_feat_original[<span class="number">0</span>] = new_test_feat_original[<span class="number">0</span>] - <span class="number">1</span></span><br><span class="line">U_size = <span class="number">10000</span></span><br><span class="line">U_ = U.sample(n=U_size, random_state=<span class="number">123</span>, axis=<span class="number">0</span>)</span><br><span class="line">U_id = U_.iloc[:, :<span class="number">1</span>]</span><br><span class="line">Uid = U.iloc[:, :<span class="number">0</span>]</span><br><span class="line">id = np.array(U_id)</span><br><span class="line"><span class="comment"># U 剔除 U'</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">100000</span>):</span><br><span class="line">    <span class="keyword">if</span> i <span class="keyword">in</span> id:</span><br><span class="line">        U = U.drop(i, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">else</span>:<span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line">U_ = U_.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">U_.to_csv(<span class="string">"U_.csv"</span>)</span><br><span class="line">U.to_csv(<span class="string">"U.csv"</span>)</span><br><span class="line"><span class="comment"># 保存减少之后的运行时间</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>矩阵按某列id排序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">id = np.array(pred_U_view1_id)</span><br><span class="line">U_array = np.array(U_)</span><br><span class="line">U_array_add = U_array[id<span class="number">-1</span>]<span class="comment">######view2</span></span><br><span class="line">U_array_add= pd.DataFrame.from_dict(U_array_add)</span><br><span class="line"><span class="comment">#U_view2_feat = U_view2_test_array_add</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>画auc，roc曲线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> auc</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y_true, prob_test, pos_label=<span class="number">0</span>)</span><br><span class="line">roc_auc = auc(fpr, tpr)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">'Receiver Operating Characteristic'</span>)</span><br><span class="line">plt.plot(fpr, tpr, </span><br><span class="line">label=<span class="string">'AUC = %0.2f'</span>% roc_auc)</span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>],<span class="string">'r--'</span>,marker = <span class="string">'o'</span>)</span><br><span class="line">plt.xlim([<span class="number">-0.1</span>,<span class="number">1.2</span>])</span><br><span class="line">plt.ylim([<span class="number">-0.1</span>,<span class="number">1.2</span>])</span><br><span class="line">plt.ylabel(<span class="string">'True Positive Rate'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'False Positive Rate'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
</li>
<li><p>特征重要性排序</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  </span><br><span class="line">fig, ax &#x3D; plt.subplots(figsize&#x3D;(12,12))</span><br><span class="line">#xgboost的内建画变量重要性的方法需要传axes对象</span><br><span class="line">xgb.plot_importance(clf1, height&#x3D;0.8, ax&#x3D;ax)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li><p>按索引提取多行数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">index &#x3D; df_9982.index.tolist()</span><br><span class="line">test_feat_2w &#x3D; test_feat.iloc[index,:]</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h5 id="学到的一些经验"><a href="#学到的一些经验" class="headerlink" title="学到的一些经验"></a>学到的一些经验</h5><ul>
<li><p>stacking堆叠模型不能单纯用全部训练集训练模型再对训练集做预测，这样一定会过拟合，要用交叉验证法，得到训练集预测值</p>
</li>
<li><p>反欺诈异常检测数据类别不平衡，不能用一般评价指标</p>
</li>
<li><p>要学会用生成数据文件的行式减少运行时间</p>
</li>
</ul>
<h1 id="机器学习回顾8-：一些基础"><a href="#机器学习回顾8-：一些基础" class="headerlink" title="机器学习回顾8 ：一些基础"></a>机器学习回顾8 ：一些基础</h1><h3 id="机器学习0"><a href="#机器学习0" class="headerlink" title="机器学习0"></a>机器学习0</h3><blockquote>
<p><em>寒假的学习虽然进度很快，但是开学后并没有及时的复习，忘记了很多，所以开此博客，督促学习，一周一更。目标在一年之内学完Ng的机器学习与深度学习课程，结合周志华《机器学习》，真正入门机器学习领域！</em><br><strong><em>切忌好高骛远，急于求成，精度远比速度重要！</em></strong></p>
</blockquote>
<p>（一）机器学习分类</p>
<ul>
<li>监督学习：数据集有标记，结果已知，主要应用于回归与分类问题。 </li>
</ul>
<ol>
<li>回归问题：<br>预测连续值属性，如房价的预测，通过对数据集进行线性拟合，得到模型进 行预测。</li>
<li>分类问题：<br>生成离散值，对数据进行分类，如对肿瘤的分类，生成0/1离散值来推测良性或恶性。</li>
</ol>
<ul>
<li>无监督学习：数据集无标记，机器对数据集特征自动生成不同的分类簇，实现对数据按不同特征的分类。典型方法有聚类，降维。</li>
</ul>
<p>（二）线性回归算法</p>
<p>（1）算法思路：<br>建模—写出代价函数—梯度下降求最优参—得到线性模型—应用</p>
<p>（2）多变量线性回归详述：</p>
<p>   0.建模：</p>
<p> <img src="https://note.youdao.com/yws/api/personal/file/59DA3B0207214C28BA864E18E89E2CBB?method=download&shareKey=903747661f5b06f0974112e6992824e7" alt=""></p>
<blockquote>
<p>注：假设函数</p>
</blockquote>
<p>1.代价函数:</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/1C1964907F874598AC123B3E34BEE7B4?method=download&shareKey=3ad7f7b2fab7f1080aca7e075c549ed0" alt=""></p>
<blockquote>
<p>注：代价函数常采取平方误差，用于衡量模型的泛化能力，即性能量度。通过预测结果h(x)与真实值y进行比较，得到误差评估函数—代价函数</p>
</blockquote>
<p>代码实现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def computeCost(X,y,theta):</span><br><span class="line"></span><br><span class="line">    inner &#x3D; np.power(((X*theta.T)-y),2)</span><br><span class="line">    </span><br><span class="line">    return np.sum(inner)&#x2F;(2*len(X))</span><br><span class="line">    &#x2F;&#x2F;这里采用向量化处理</span><br></pre></td></tr></table></figure>


<p>2.批量梯度下降:</p>
<blockquote>
<p>1.批量指每次同步更新参数时，对整个训练集遍历。</p>
<p>2.算法作用：通过不断更新参数值，实现最小化代价函数，逐步达到局部最小值。</p>
<p>3.学习率：决定每次下降幅度大小，太大会导致无法收敛，太小速度慢，因为下降过程中，偏导递减，没必要减少学习率，就能自动采取更小的幅度。</p>
</blockquote>
<p><img src="https://note.youdao.com/yws/api/personal/file/4206F73504D74752B6699541B64E3C21?method=download&shareKey=c265319ed15c4a95cb5e9afb4b1bea83" alt=""><br>1）实践—特征放缩</p>
<blockquote>
<p>解决多维特征问题时，需要保证特征尺度相近，有助于梯度下降更快收敛</p>
</blockquote>
<p><img src="https://note.youdao.com/yws/api/personal/file/0C61B773BF9A4D79B55FE62290C8656D?method=download&shareKey=2d1fa3241ecc20499d5fe7ff30e8e69e" alt=""></p>
<p>2）实践—学习率选取<br>通常考虑 0.01，0.03，0.1，0.3 ，1， 3， 10</p>
<p>附录框架图<br><img src="https://note.youdao.com/yws/api/personal/file/B1084655D7654E17B5D3A5E6369E0BE0?method=download&shareKey=0fffe1949bf9962db4dadfd5c27438a4" alt=""></p>
<h1 id="机器学习回顾9-：数据预处理"><a href="#机器学习回顾9-：数据预处理" class="headerlink" title="机器学习回顾9 ：数据预处理"></a>机器学习回顾9 ：数据预处理</h1><hr>
<h2 id="title-数据集处理"><a href="#title-数据集处理" class="headerlink" title="title: 数据集处理"></a>title: 数据集处理</h2><h3 id="数据集处理"><a href="#数据集处理" class="headerlink" title="数据集处理"></a>数据集处理</h3><blockquote>
<p>实践与理论并行，本篇通过spider实现对数据集的处理</p>
</blockquote>
<h4 id="主要步骤"><a href="#主要步骤" class="headerlink" title="主要步骤"></a>主要步骤</h4><p>1.导入标准库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import pandas as pd</span><br></pre></td></tr></table></figure>

<p>2.导入数据集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset &#x3D; pd.read_csv(&#39;Data.csv&#39;)</span><br><span class="line">X &#x3D; dataset.iloc[:,:-1].values</span><br><span class="line">y &#x3D; dataset.iloc[:,3].values</span><br></pre></td></tr></table></figure>


<p>3.分类数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import LabelEncoder, OneHotEncoder</span><br><span class="line">labelencoder_X &#x3D; LabelEncoder()</span><br><span class="line">X[:,0] &#x3D; labelencoder_X.fit_transform(X[:,0])#将国家名转化成数字标签</span><br><span class="line">onehotencoder &#x3D; OneHotEncoder(categorical_features &#x3D; [0])</span><br><span class="line">X &#x3D; onehotencoder.fit_transform(X).toarray()#对国家进行虚拟编码</span><br><span class="line">labelencoder_y &#x3D; LabelEncoder()</span><br><span class="line">y &#x3D; labelencoder_y.fit_transform(y)#对y标签编码</span><br></pre></td></tr></table></figure>


<p>4.分割数据集为训练集，测试集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test &#x3D; train_test_split(X,y,test_size &#x3D; 0.2, random_state &#x3D; 0)</span><br></pre></td></tr></table></figure>
<p>5.特征缩放</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">sc_X &#x3D; StandardScaler()</span><br><span class="line">X_train &#x3D; sc_X.fit_transform(X_train)</span><br><span class="line">X_test &#x3D; sc_X.transform(X_test)</span><br></pre></td></tr></table></figure>

<p>6.损失数据的处理</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import Imputer #ctrl+I 看定义</span><br><span class="line">imputer &#x3D; Imputer(missing_values &#x3D; &#39;NaN&#39;,strategy &#x3D; &#39;mean&#39;,axis &#x3D; 0)</span><br><span class="line">imputer &#x3D; imputer.fit(X[:,1:3])#所有行的第二列，第三列</span><br><span class="line">X[:,1:3] &#x3D; imputer.transform(X[:,1:3])</span><br></pre></td></tr></table></figure>

<p>7.模板</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#导入标准库</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import pandas as pd</span><br><span class="line">#导入数据集</span><br><span class="line">dataset &#x3D; pd.read_csv(&#39;Data.csv&#39;)</span><br><span class="line">X &#x3D; dataset.iloc[:,:-1].values</span><br><span class="line">y &#x3D; dataset.iloc[:,3].values</span><br><span class="line">#对数据集分割成 训练集 测试集 </span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test &#x3D; train_test_split(X,y,test_size &#x3D; 0.2, random_state &#x3D; 0)</span><br><span class="line">#随机确定测试集 训练集</span><br></pre></td></tr></table></figure>



<h1 id="机器学习回顾10-：半监督学习中的协同训练算法"><a href="#机器学习回顾10-：半监督学习中的协同训练算法" class="headerlink" title="机器学习回顾10 ：半监督学习中的协同训练算法"></a>机器学习回顾10 ：半监督学习中的协同训练算法</h1><h3 id="半监督学习中的协同训练算法"><a href="#半监督学习中的协同训练算法" class="headerlink" title="半监督学习中的协同训练算法"></a>半监督学习中的协同训练算法</h3><blockquote>
<p>使用两个或多个学习器,这些学习器挑选若干个置信度高的未标记示例进行相互标记，从而使模型更新</p>
</blockquote>
<ul>
<li>数据集要求：有两个充分冗余（sufficient and redundant）的视图（view）<blockquote>
<p>一，每个数据集都足以描述该问题，即如果训练集足够，在每个属性集上都足以学得一个强学习器</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>二，给定标记时，每个属性集都都条件独立于另一个属性集</p>
</blockquote>
<ul>
<li>算法概述<blockquote>
<p>先利用两组独立的有标记数据训练两个分类器，协同训练时，每个分类器从未标记数据中挑选出置信度较高（more probably）的示例进行标记，并将新标记示例加入另一个分类器的标记训练集中，从而利用新标记数据进行更新。</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>“co-training方法是一类半监督方法，是一个框架，核心就是利用少量已标记样本，通过两个（或多个）模型去学习，对未标记样本进行标记，挑选most confidently的样本加入已标记样本阵营。”</p>
</blockquote>
<p><img src="https://note.youdao.com/yws/api/personal/file/CDD3EA0E7FC74B6D9E71EE03E01483EB?method=download&shareKey=c1e527c4398b8a35775c24c3dcb7b8d6" alt=""></p>
<ul>
<li>co-training理论分析<br>//公式目前看不懂</li>
</ul>
<p><a href="http://note.youdao.com/noteshare?id=3f6454d9a918884954e800e570a31fcc" target="_blank" rel="noopener">co-training 周志华</a></p>
<h1 id="机器学习回顾11-：机器学习—贝叶斯分类器"><a href="#机器学习回顾11-：机器学习—贝叶斯分类器" class="headerlink" title="机器学习回顾11 ：机器学习—贝叶斯分类器"></a>机器学习回顾11 ：机器学习—贝叶斯分类器</h1><h1 id="机器学习—贝叶斯分类器"><a href="#机器学习—贝叶斯分类器" class="headerlink" title="机器学习—贝叶斯分类器"></a>机器学习—贝叶斯分类器</h1><h3 id="算法原理-1"><a href="#算法原理-1" class="headerlink" title="算法原理"></a>算法原理</h3><blockquote>
<p>一种基于贝叶斯理论的分类算法，通过学习某对象的联合概率分布（即先验概率分布与条件概率分布），计算该对象的后验概率分布，即该对象属于每个类的概率分布，选取概率最大的类作为分类结果。<br>scikit中有多种朴素贝叶斯分类器，区别在于假设了不同的概率分布。</p>
</blockquote>
<ul>
<li>GaussianNB（高斯分类器）假设特征的条件概率分布满足高斯分布</li>
<li>MultinomialNB(多项式贝叶斯分类器) 满足多项式分布</li>
<li>BernoulliNB(伯努利贝叶斯分类器)满足二项分布，特征取值只能为0，1</li>
</ul>
<h3 id="数学推导（朴素贝叶斯）"><a href="#数学推导（朴素贝叶斯）" class="headerlink" title="数学推导（朴素贝叶斯）"></a>数学推导（朴素贝叶斯）</h3><p><img src="https://note.youdao.com/yws/api/personal/file/eb633551b72d6463c1576b4e3b741878?method=download&shareKey=18715c481be19cc2cda93c60dd5b77fd" alt=""></p>
<h3 id="代码实现实例-2"><a href="#代码实现实例-2" class="headerlink" title="代码实现实例"></a>代码实现实例</h3>
            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'http-miccall-tech'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://yoursite.com/2019/04/08/2019/taylor/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://yoursite.com/2019/04/08/2019/taylor/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//http-miccall-tech.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener" style="border-bottom: none;">hexo</a></li>
                <li>Design: <a href="http://miccall.tech " target="_blank" rel="noopener" style="border-bottom: none;">miccall</a></li>
            </ul>
            
                <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
